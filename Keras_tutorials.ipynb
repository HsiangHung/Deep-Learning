{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset in training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((537, 8), (537,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "train_size = int(dataset.shape[0]*0.7)\n",
    "print (train_size)\n",
    "X_train = dataset[:train_size, :8]\n",
    "Y_train = dataset[:train_size, 8]\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((231, 8), (231,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = dataset[train_size:, :8]\n",
    "Y_test = dataset[train_size:, 8]\n",
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "### (a) model I: 3-layers, node numbers of input and hidden layers are 12 and 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use logarithmic loss, which for a binary classification problem is defined in Keras as “binary_crossentropy“. The efficient gradient descent algorithm “adam” is an efficient default in Keras. Learn more about the Adam optimization algorithm in the paper [“Adam: A Method for Stochastic Optimization“](https://arxiv.org/abs/1412.6980). The metric used here is \"accuracy\". Adam is a stochastic gradient method. \n",
    "\n",
    "Here we use **[relu](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)** for the activation function for the first two layers, and **sigmoid** to indicate probability for the output layer. **relu** activation function is popular in deep learning. Later we will revisit the same problem but using **sigmoid** activation and compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fitting\n",
    "\n",
    "We can set up number of epoches as **nb_epoch**, and size of each mini-batch as **batch_size**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e89ae10>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, nb_epoch=150, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/231 [===>..........................] - ETA: 1s  Loss:  0.528315976069  , acc: 0.757575758092\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test)\n",
    "print('  Loss: ', scores[0], ' , acc:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **acc** is the accuracy defined the ratio we have right prediction. This is the same as doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757575757576\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "a = numpy.dot(rounded-Y_test, rounded-Y_test)\n",
    "print(1.0-a/len(rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further observe the probability of the Pima Indian patients to have diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/231 [===>..........................] - ETA: 0s[[ 0.02870761]\n",
      " [ 0.2803773 ]\n",
      " [ 0.33776325]\n",
      " [ 0.64599019]\n",
      " [ 0.36038035]\n",
      " [ 0.14201277]\n",
      " [ 0.08908633]\n",
      " [ 0.12896512]\n",
      " [ 0.85859615]\n",
      " [ 0.89892173]]\n"
     ]
    }
   ],
   "source": [
    "print (model.predict_proba(X_test)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Double mini-batch size\n",
    "\n",
    "Now we can double the mini-batch size and train the model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/231 [===>..........................] - ETA: 0s  Loss:  0.572329931896  , acc: 0.78354978355\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, nb_epoch=150, batch_size=20, verbose=0)\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print('  Loss: ', scores[0], ' , acc:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "#model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/231 [===>..........................] - ETA: 0s  Loss:  0.64257547427  , acc: 0.658008658525\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, nb_epoch=150, batch_size=10, verbose=0)\n",
    "scores = model.evaluate(X_test, Y_test);\n",
    "print('  Loss: ', scores[0], ' , acc:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) model II: 3-layers, node numbers of input and hidden layers are 20 and 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(20, input_dim=8, init='uniform', activation='relu'))\n",
    "model2.add(Dense(12, init='uniform', activation='relu'))\n",
    "model2.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/231 [===>..........................] - ETA: 0s  Loss:  0.484604746748  , acc: 0.796536796537\n"
     ]
    }
   ],
   "source": [
    "model2.fit(X_train, Y_train, nb_epoch=150, batch_size=10, verbose=0)\n",
    "scores = model2.evaluate(X_test, Y_test);\n",
    "print('  Loss: ', scores[0], ' , acc:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) model III: 3-layers, node numbers are 12 and 8 but all using relu activation function\n",
    "\n",
    "Now let's do deep learning by considering all activation function with **sigmoid** function. The accuracy is worse than using **relu**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/231 [===>..........................] - ETA: 1s  Loss:  0.563818572404  , acc: 0.679653679912\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(12, input_dim=8, init='uniform', activation='sigmoid'))\n",
    "model3.add(Dense(8, init='uniform', activation='sigmoid'))\n",
    "model3.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.fit(X_train, Y_train, nb_epoch=150, batch_size=10, verbose=0)\n",
    "scores = model3.evaluate(X_test, Y_test);\n",
    "print('  Loss: ', scores[0], ' , acc:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02870761]\n",
      " [ 0.2803773 ]\n",
      " [ 0.33776325]\n",
      " [ 0.64599019]\n",
      " [ 0.36038035]\n",
      " [ 0.14201277]\n",
      " [ 0.08908633]\n",
      " [ 0.12896512]\n",
      " [ 0.85859615]\n",
      " [ 0.89892173]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions.shape\n",
    "print (predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "rounded = [round(x[0]) for x in predictions]\n",
    "print (rounded[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/231 [=======================>......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "predictions2 = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "* 1. [Develop Your First Neural Network in Python With Keras Step-By-Step](http://machinelearningmastery.com/tutorial-first-neural-network-python-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
